---
layout: post
title:  "[Practice]Prometheus & Grafana Install - Part1"
date:   2021-04-18T21:35:52-05:00
author: Lee
categories: Kubernetes
---

## System Environment:
    OS: Windows 10 
    k8s: Docker Desktop (Kubernetes Enabled)
    Docker Version: v20.10.5
    Helm Version: v3.5.3+g041ce5a



#### Helm Command Check 

    helm version --short
	v3.5.3+g041ce5a
 
#### Helm Repo Add 
	helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
	"prometheus-community" has been added to your repositories  

	helm repo list
	NAME                    URL
	prometheus-community    https://prometheus-community.github.io/helm-charts

#### Helm Install Prometheus 
	helm install prometheus -n monitoring --create-namespace prometheus-community/prometheus
	 (If you want to uninstall using helm >>> helm uninstall prometheus -n monitoring)
    NAME: prometheus
    LAST DEPLOYED: Sun Apr 18 20:42:04 2021
    NAMESPACE: monitoring
    STATUS: deployed
    REVISION: 1
    TEST SUITE: None
    NOTES:
    The Prometheus server can be accessed via port 80 on the following DNS name from within your cluster:
    prometheus-server.monitoring.svc.cluster.local


    Get the Prometheus server URL by running these commands in the same shell:
    export POD_NAME=$(kubectl get pods --namespace monitoring -l "app=prometheus,component=server" -o jsonpath="{.items[0].metadata.name}")  
    kubectl --namespace monitoring port-forward $POD_NAME 9090


    The Prometheus alertmanager can be accessed via port 80 on the following DNS name from within your cluster:
    prometheus-alertmanager.monitoring.svc.cluster.local


    Get the Alertmanager URL by running these commands in the same shell:
    export POD_NAME=$(kubectl get pods --namespace monitoring -l "app=prometheus,component=alertmanager" -o jsonpath="{.items[0].metadata.name}")
    kubectl --namespace monitoring port-forward $POD_NAME 9093
    #################################################################################
    ######   WARNING: Pod Security Policy has been moved to a global property.  #####
    ######            annotations                                               #####
    ######            (e.g. .Values.nodeExporter.podSecurityPolicy.annotations) #####
    #################################################################################


    The Prometheus PushGateway can be accessed via port 9091 on the following DNS name from within your cluster:
    prometheus-pushgateway.monitoring.svc.cluster.local


    Get the PushGateway URL by running these commands in the same shell:
    export POD_NAME=$(kubectl get pods --namespace monitoring -l "app=prometheus,component=pushgateway" -o jsonpath="{.items[0].metadata.name}")
    kubectl --namespace monitoring port-forward $POD_NAME 9091

    For more information on running Prometheus, visit:
    https://prometheus.io/


	kubectl.1.15.exe get ns           
    NAME              STATUS   AGE
    argo              Active   21h
    default           Active   3d22h
    ingress-nginx     Active   21h
    kube-node-lease   Active   3d22h
    kube-public       Active   3d22h
    kube-system       Active   3d22h
    monitoring        Active   11s


	helm ls -n monitoring             << Added Chart(prometheus) >>
    NAME            NAMESPACE       REVISION        UPDATED                                                                                   STATUS   CHART                   APP VERSION
    prometheus      monitoring      1               2021-04-18 21:05:31.2198078 +0900 JST                                                     deployed prometheus-13.8.0       2.26.0


	kubectl get all -n monitoring
    NAME                                                 READY   STATUS              RESTARTS   AGE
    pod/prometheus-alertmanager-ccf8f68cd-6j5jh          2/2     Running             0          39s
    pod/prometheus-kube-state-metrics-685b975bb7-59xfs   1/1     Running             0          39s
    pod/prometheus-node-exporter-4kfvm                   0/1     RunContainerError   2          39s
    pod/prometheus-pushgateway-74cb65b858-6jm5g          1/1     Running             0          39s
    pod/prometheus-server-d9fb67455-lsggt                2/2     Running             0          39s

    NAME                                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
    service/prometheus-alertmanager         ClusterIP   10.111.184.160   <none>        80/TCP     39s
    service/prometheus-kube-state-metrics   ClusterIP   10.103.235.112   <none>        8080/TCP   39s
    service/prometheus-node-exporter        ClusterIP   None             <none>        9100/TCP   39s
    service/prometheus-pushgateway          ClusterIP   10.96.39.71      <none>        9091/TCP   39s
    service/prometheus-server               ClusterIP   10.104.162.18    <none>        80/TCP     39s

    NAME                                      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
    daemonset.apps/prometheus-node-exporter   1         1         0       1            0           <none>          39s

    NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
    deployment.apps/prometheus-alertmanager         1/1     1            1           39s
    deployment.apps/prometheus-kube-state-metrics   1/1     1            1           39s
    deployment.apps/prometheus-pushgateway          1/1     1            1           39s
    deployment.apps/prometheus-server               1/1     1            1           39s

    NAME                                                       DESIRED   CURRENT   READY   AGE
    replicaset.apps/prometheus-alertmanager-ccf8f68cd          1         1         1       39s
    replicaset.apps/prometheus-kube-state-metrics-685b975bb7   1         1         1       39s
    replicaset.apps/prometheus-pushgateway-74cb65b858          1         1         1       39s
    replicaset.apps/prometheus-server-d9fb67455                1         1         1       39s

#### Error (Trouble Shooting)
!! RunContainerError at node-exporter !!
    pod/prometheus-node-exporter-4kfvm                   0/1     RunContainerError



	kubectl describe pod/prometheus-node-exporter-4kfvm -n monitoring       
    Name:         prometheus-node-exporter-4kfvm     
    Namespace:    monitoring
    Priority:     0
    Node:         docker-desktop/192.168.65.4        
    Start Time:   Sun, 18 Apr 2021 21:05:31 +0900    
    Labels:       app=prometheus
                chart=prometheus-13.8.0
                component=node-exporter
                controller-revision-hash=858cd5b95b
                heritage=Helm
                pod-template-generation=1
                release=prometheus
    Annotations:  <none>
    Status:       Running
    IP:           192.168.65.4
    IPs:
    IP:           192.168.65.4
    Controlled By:  DaemonSet/prometheus-node-exporter
    Containers:
    prometheus-node-exporter:
        Container ID:  docker://fb3eeb442aec1df88d72efa52cf5b85a91dbae96f1edff3b31cc6802c5060f8b
        Image:         quay.io/prometheus/node-exporter:v1.1.2
        Image ID:      docker-pullable://quay.io/prometheus/node-exporter@sha256:22fbde17ab647ddf89841e5e464464eece111402b7d599882c2a3393bc0d2810
        Port:          9100/TCP
        Host Port:     9100/TCP
        Args:
        --path.procfs=/host/proc
        --path.sysfs=/host/sys
        --path.rootfs=/host/root
        --web.listen-address=:9100
        State:          Waiting
        Reason:       CrashLoopBackOff
        Last State:     Terminated
        Reason:       ContainerCannotRun
        Message:      path / is mounted on / but it is not a shared or slave mount
        Exit Code:    128
        Started:      Sun, 18 Apr 2021 21:07:03 +0900
        Finished:     Sun, 18 Apr 2021 21:07:03 +0900
        Ready:          False
        Restart Count:  4
        Environment:    <none>
        Mounts:
        /host/proc from proc (ro)
        /host/root from root (ro)
        /host/sys from sys (ro)
        /var/run/secrets/kubernetes.io/serviceaccount from prometheus-node-exporter-token-f6hxf (ro)
    Conditions:
    Type              Status
    Initialized       True
    Ready             False
    ContainersReady   False
    PodScheduled      True
    Volumes:
    proc:
        Type:          HostPath (bare host directory volume)
        Path:          /proc
        HostPathType:
    sys:
        Type:          HostPath (bare host directory volume)
        Path:          /sys
        HostPathType:
    root:
        Type:          HostPath (bare host directory volume)
        Path:          /
        HostPathType:
    prometheus-node-exporter-token-f6hxf:
        Type:        Secret (a volume populated by a Secret)
        SecretName:  prometheus-node-exporter-token-f6hxf
        Optional:    false
    QoS Class:       BestEffort
    Node-Selectors:  <none>
    Tolerations:     node.kubernetes.io/disk-pressure:NoSchedule
                    node.kubernetes.io/memory-pressure:NoSchedule
                    node.kubernetes.io/network-unavailable:NoSchedule
                    node.kubernetes.io/not-ready:NoExecute
                    node.kubernetes.io/pid-pressure:NoSchedule
                    node.kubernetes.io/unreachable:NoExecute
                    node.kubernetes.io/unschedulable:NoSchedule
    Events:
    Type     Reason     Age                  From                     Message
    ----     ------     ----                 ----                     -------
    Normal   Scheduled  2m13s                                         Successfully assigned monitoring/prometheus-node-exporter-4kfvm to docker-desktop
    Normal   Pulled     42s (x5 over 2m13s)  kubelet, docker-desktop  Container image "quay.io/prometheus/node-exporter:v1.1.2" already present on machine
    Normal   Created    42s (x5 over 2m13s)  kubelet, docker-desktop  Created container prometheus-node-exporter
    Warning  Failed     42s (x5 over 2m13s)  kubelet, docker-desktop  Error: failed to start container "prometheus-node-exporter": Error response from daemon: path / is mounted on / but it is not a shared or slave mount
    Warning  BackOff    11s (x8 over 106s)   kubelet, docker-desktop  Back-off restarting failed container


	kubectl.1.15.exe get pod -n monitoring     
    NAME                                             READY   STATUS             RESTARTS   AGE
    prometheus-alertmanager-ccf8f68cd-6j5jh          2/2     Running            0          3m57s
    prometheus-kube-state-metrics-685b975bb7-59xfs   1/1     Running            0          3m57s
    prometheus-node-exporter-4kfvm                   0/1     CrashLoopBackOff   5          3m57s
    prometheus-pushgateway-74cb65b858-6jm5g          1/1     Running            0          3m57s
    prometheus-server-d9fb67455-lsggt                2/2     Running            0          3m57s


	kubectl.1.15.exe get svc -n monitoring
    NAME                            TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
    prometheus-alertmanager         ClusterIP   10.111.184.160   <none>        80/TCP     5m56s
    prometheus-kube-state-metrics   ClusterIP   10.103.235.112   <none>        8080/TCP   5m56s
    prometheus-node-exporter        ClusterIP   None             <none>        9100/TCP   5m56s
    prometheus-pushgateway          ClusterIP   10.96.39.71      <none>        9091/TCP   5m56s
    prometheus-server               ClusterIP   10.104.162.18    <none>        80/TCP     5m56s



	kubectl port-forward prometheus-server-d9fb67455-lsggt -n monitoring 8080:80
    Forwarding from 127.0.0.1:8080 -> 80
    Forwarding from [::1]:8080 -> 80   

Just ignore Error Message and try to access to prometheus server  
-->> Fail to access (Can't open browse)

#### Workaround (Trouble Shooting)

Continue to investigate about the error   
[https://github.com/prometheus-community/helm-charts/pull/757/files/eab971822fa84bf22c5433fdf837ce1830bafe86#diff-141ccf9d3c2f15b42cbb983368df872ea9bbafa24051a316b62062f2171def87](https://github.com/prometheus-community/helm-charts/pull/757/files/eab971822fa84bf22c5433fdf837ce1830bafe86#diff-)
[https://github.com/prometheus-community/helm-charts/issues/467](https://github.com/prometheus-community/helm-charts/issues/467)  

It seems to be related to a storage problem. ( root volume config )
Let's try the following workaround ( delete root volume config )

	kubectl.1.15.exe edit daemonset.apps/prometheus-node-exporter -n monitoring
    daemonset.apps/prometheus-node-exporter edited
    
   **Remove below parts** 

    containers: 
    - args:
        - --path.rootfs=/host/root      **< First Part >**
    ....
    volumeMounts: part
        - mountPath: /host/root             **< Second Part >**
          mountPropagation: HostToContainer **< Second Part >**
          name: root                        **< Second Part >**
          readOnly: true                    **< Second Part >**
    ....
    volumes: part
        - hostPath:        **< Third Part >**
            path: /        **< Third Part >**
            type: ""       **< Third Part >**
          name: root       **< Third Part >**


	kubectl.1.15.exe get all -n monitoring
    NAME                                                 READY   STATUS    RESTARTS   AGE
    pod/prometheus-alertmanager-ccf8f68cd-6j5jh          2/2     Running   0          19m
    pod/prometheus-kube-state-metrics-685b975bb7-59xfs   1/1     Running   0          19m
    pod/prometheus-node-exporter-c494x                   1/1     Running   0          20s       **<<- Running!**
    pod/prometheus-pushgateway-74cb65b858-6jm5g          1/1     Running   0          19m
    pod/prometheus-server-d9fb67455-lsggt                2/2     Running   0          19m

    NAME                                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE
    service/prometheus-alertmanager         ClusterIP   10.111.184.160   <none>        80/TCP     19m
    service/prometheus-kube-state-metrics   ClusterIP   10.103.235.112   <none>        8080/TCP   19m
    service/prometheus-node-exporter        ClusterIP   None             <none>        9100/TCP   19m
    service/prometheus-pushgateway          ClusterIP   10.96.39.71      <none>        9091/TCP   19m
    service/prometheus-server               ClusterIP   10.104.162.18    <none>        80/TCP     19m

    NAME                                      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
    daemonset.apps/prometheus-node-exporter   1         1         1       1            1           <none>          19m

    NAME                                            READY   UP-TO-DATE   AVAILABLE   AGE
    deployment.apps/prometheus-alertmanager         1/1     1            1           19m
    deployment.apps/prometheus-kube-state-metrics   1/1     1            1           19m
    deployment.apps/prometheus-pushgateway          1/1     1            1           19m
    deployment.apps/prometheus-server               1/1     1            1           19m

    NAME                                                       DESIRED   CURRENT   READY   AGE
    replicaset.apps/prometheus-alertmanager-ccf8f68cd          1         1         1       19m
    replicaset.apps/prometheus-kube-state-metrics-685b975bb7   1         1         1       19m
    replicaset.apps/prometheus-pushgateway-74cb65b858          1         1         1       19m
    replicaset.apps/prometheus-server-d9fb67455                1         1         1       19m


	kubectl port-forward service/prometheus-server -n monitoring 8080:80        
    Forwarding from 127.0.0.1:8080 -> 9090
    Forwarding from [::1]:8080 -> 9090

#### Succeed
Try to access 127.0.0.1:8080  
**It worked!!!!!!**

<img src="/assets/kubernetes/prometheus_main.png">



## Reference Site:
    [https://zaki-hmkc.hatenablog.com/entry/2020/11/14/104538](https://zaki-hmkc.hatenablog.com/entry/2020/11/14/104538) 
    [https://github.com/grafana/helm-charts/tree/main/charts/grafana](https://github.com/grafana/helm-charts/tree/main/charts/grafana)
    [https://github.com/prometheus-community/helm-charts](https://github.com/prometheus-community/helm-charts)
<!--stackedit_data:
eyJoaXN0b3J5IjpbLTE4MTY5NDQ4MzAsLTgwNDQyNDI2OCwtMT
A4MjkwNzI3OV19
-->